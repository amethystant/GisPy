A third feature of our data that may constrain unified accounts of modality effects is that the magnitude of modality differences is greatest when participants initiate their recall from the start of the list. This suggests that a major factor in determining the modality effect in both IFR and ISR is the greater resistance to output interference observed with auditory stimuli (including visual words that are read aloud) relative to words in the visual silent presentation condition (Cowan et al., 2002, 2004). One explanation for the resilience of auditory items within our data sets is that auditory words are stored with more enriched sets of features than visual items (e.g., Nairne, 1990; Neath, 2000), and that recalled list items interfere with the recall of as yet to-be-remembered items. If we further assume that the internalized voice that accompanies silent written recall at output is more similar to the internalized voice that accompanies covert phonological recoding in the visual silent presentation condition, then as recall progresses the differences in the effect of subsequent recalls (output interference) on visual relative to auditory yet-to-be-recalled items will increase.
A fourth and final feature of our data that may constrain unified accounts of IFR and ISR is the confirmation of inverse modality effects (Beaman, 2002; Macken et al., 2016): visual recall advantages that occur in early mid serial positions with medium to long list lengths. Consistent with Macken et al. (2016), we assume that the modality of presentation affects the way that all the list items are processed. We agree that presenting stimuli in the visual silent conditions may be more conducive to cumulative forward-ordered rehearsal than visual read aloud as the former but not the latter is unimpeded by the need to articulate or vocalize each currently presented item. We are also willing to accept that participants might either feel a greater necessity to rehearse the visual silent items relative to the words in the auditory condition in order to form groups or subsequences of lists and/or be less able to incorporate the current auditory presented word into a cumulatively expanding rehearsal set. The benefits of cumulative forwardordered rehearsal may be greatest not at the start of the list but at early mid list positions (see Grenfell-Essam et al., 2013), and the benefit may be greatest at longer list lengths, where there might be both greater rehearsal opportunities and where the difficulty in recalling unrehearsed early list items might be more difficult (see Ward, 2002). Currently, many contemporary accounts of IFR and ISR (e.g., the SIMPLE model, Brown et al., 2007; the feature model, e.g., Nairne, 1990; Neath, 2000; and the Farrell, 2012 model) do not incorporate an account of rehearsal. However, our data suggest that recall of read aloud stimuli is reasonably similar to the recall of auditory stimuli, and we do not find the lowered levels of overall performance observed in the read aloud conditions of Macken et al. (2016). Of course, there are many differences between the methodologies used in our study and that of Macken et al. (2016). Most notably, we used different tasks, an experiment-unique set of stimuli, words rather than consonants and a rate of presentation of one word per second that was slightly slower than that standardly used by Macken et al. (2016; 750 ms per word).
Our preferred explanation of our data is that the modality of presentation affects the processing of the entire list of items. We assume that longer lists are parsed into multiple groups (of varying sizes), and the presentation of each auditory (or read aloud) item leads to a set of more richly encoded features than those encoded following the presentation of each visual silent item. The modality of presentation does not affect the PFR, as each item within the same modality in the list is encoded with the same richness of features. However, the encoding of relatively impoverished written recalled items will create greater relative interference for the impoverished visual items than the richly encoded auditory items, leading to improved recall of auditory over visual items on later recalls. We finally assume that participants might rehearse in a cumulative forward-ordered manner with all lists, but they may be able to rehearse longer sequences of early lists items with visual silent lists than with either auditory or read aloud lists.
In summary, we have reported a systematic exploration of the modality effects across a wide range of list lengths in both IFR and ISR, contrasting visual silent presentation with both auditory (Experiment 1) and read aloud (Experiment 2) presentation. We have shown that the magnitude and extent of modality effects are similar across tasks when the list length is controlled, and we have also shown inverse modality effects in both tasks in early mid list positions for medium to long lists. We believe these findings encourage attempts to provide a unified account of both IFR and ISR. We believe that in both tasks, modality effects arise through the greater resilience of auditory items to output interference. Our data provide four findings that will constrain the development of such a theory, and additionally provide a rich data set that could be used to model the development of the serial position curve with each successively presented list item.
A final point before discussing the implications of the findings for parsing theories is that whereas the results demonstrate that the parser anticipates negation as a licensor for the genitive NP, they are not conclusive as to whether alternative licensors are considered in parallel. Recall that in the offline sentence fragment completion task (Experiment 1) alternative licensors for the genitive NP (in particular, adverbs) were offered, albeit infrequently. This, together with an active prediction of a negated verb in the online task, indicates that in the current stimulus set the combination of grammatical, word-order, and frequency considerations disfavours most alternative licensors. Yet, I remain agnostic whether, during online processing of the experimental sentences, the few remaining possibilities (in particular, numerals or adverbs) are fully disregarded or whether they are considered in parallel with the genitive-of-negation structure.
As mentioned earlier, the results from Experiments 2 and 3 are notable as they point to anticipatory projection of multiple heads—that is, the verb and negation. Thus they argue against strongly bottom-up approaches to structure building such as headdriven parsing models (Abney, 1989; Mulders, 2003; Pritchett, 1992) by demonstrating that the verb and negation heads are projected ahead of bottom-up input on the basis of preverbal arguments. Most previous research demonstrated prediction of a verbal head in head-final languages in which such prediction could potentially be viewed as a last resort response to a ubiquitous necessity to deal with preverbal arguments, as unattached NPs would regularly result in a significant working memory load. The current demonstration that verb heads can be predicted in Russian, a non-head-final language, is notable and suggests a wider role for predictive structure-building algorithms (see also Pablos, 2006, for Spanish, Omaki et al., 2015, for English wh-dependencies). In particular, the standard left-corner parsing algorithm (Abney & Johnson, 1991; Stabler, 1994, among others) in combination with lexicalized grammar can be used to explain the results. The left-corner strategy has a top-down predictive component that operates as follows: Once the first constituent of a phrase is recognized in the bottom-up input, the prediction of a subsequent constituent can be triggered on the basis of a syntactic rule. For example, once a NP is formed bottom-up (e.g., The boy . . . ), the rule S → NP + VP is invoked, of which the NP is the left-hand-side constituent (i.e., “left corner”), which in turn triggers projection of a VP ahead of bottom-up input. In the accusative condition, upon encountering the accusative and dative NPs in the bottom-up input, the parser predicts a ditransitive verb using VP → V + NPACC + NPDAT rule (recall that in Russian word order is flexible, and hence NPACC + NPDAT can appear before the verb and serve as a left corner) and incorporates the preverbal NPs into a connected structure. Negation is not actively predicted in the accusative condition on the basis of this rule and must be added into the parsing tree on the basis of bottomup input. In the genitive condition, when NPGEN is encountered it can trigger prediction of a quirky verb (on the basis of VP → V + NPGEN rule), another nominal (NP → N + NPGEN), adverb (AdvP → Adv + NPGEN), or negative phrase with a transitive or intransitive verb NegP → Neg + V + NPGEN or NegP → Neg + V + NPGEN + NPDAT using a left-corner strategy (NPGEN is a valid left corner in all these cases as the nominal arguments can precede the head). The appearance of the NPDAT in the bottom-up input invalidates all alternatives except for the latter. Note that in the case above, postulating a lexicalized genitive-ofnegation rule NegP → Neg + V + NPGEN (+ NPDAT) is critical for rendering NPGEN into a left corner that can trigger projection of negation and verb.
As an alternative to the account above that assumed a lexicalized rule NegP → Neg + V + NPGEN (+ NPDAT), the genitive-of-negation may be encoded as a combination of structural rules in a grammarbased parser. In this case there is a rule NegP → Neg + VP and a rule whereby the structural accusative case on the verb’s direct object changes to genitive. In addition, the parser should be aware of the split licensing pattern whereby case and thematic role (on NPGEN) are not assigned by the same head. These considerations on what a parser should be able to achieve will hopefully trigger further research from grammar-based parsing theorists.
In conclusion, the findings demonstrate that in Russian, a free-word-order language, morphological case information is used by the parser for predictive structure building when it is available in the input ahead of information about the heads. Such an anticipatory mechanism allows projection of multiple lexical heads when a single head is insufficient for incremental incorporation of the bottom-up material into the parsing tree.